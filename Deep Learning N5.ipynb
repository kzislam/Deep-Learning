{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "000d92b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "warnings.filterwatrnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0813da45",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3881067889.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [11]\u001b[1;36m\u001b[0m\n\u001b[1;33m    def_init_(self,layers):\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork:\n",
    "    def_init_(self,layers):\n",
    "        self.layers=layers\n",
    "        Self.L=len(layers)\n",
    "        self.number_feature=layers[0]\n",
    "        self.number_class=layers[-1]\n",
    "    self.w={}\n",
    "    self.b={}\n",
    "    self.dw={}\n",
    "    self.db={}\n",
    "    self.setup()\n",
    "    def setup(self):\n",
    "        for i in range(1,self.L)\n",
    "        self.w[i]=if.variable(tf.random.normal(shape=(self.layer[i],self.layer[i-1])))\n",
    "        self.b[i]=if.variable(tf.random.normal(shape=(self.layer[i],1)))\n",
    "        \n",
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def forwardPass(self,A)\n",
    "    A=tf.convert_to_tensor(A,type=float32)\n",
    "    for i in range(1,self.L)\n",
    "    Z=tf.matmul(A,tf.transpose(self.w[i])+tf.transpose(self.b[i]))\n",
    "    if i!=self L-1\n",
    "       A=tf.nn.relu(z)\n",
    "    else\n",
    "       A=Z\n",
    "    return A\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba01e34",
   "metadata": {},
   "source": [
    "# Loss and upgrading parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a178b7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3415400436.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [16]\u001b[1;36m\u001b[0m\n\u001b[1;33m    for  in range(1,self.L):\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def compute_loss(self,A,Y):\n",
    "        return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(Y,A))\n",
    "    def upgrade_parameters(self,lr):\n",
    "        for  in range(1,self.L):\n",
    "            self.w[j]=assing_sub(lr*self.dw[j])\n",
    "            self.b[j]=assing_sub(lr*self.db[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "100c576a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2017812143.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [5]\u001b[1;36m\u001b[0m\n\u001b[1;33m    def predict(self.x):\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def predict(self.x):\n",
    "        A=self.forwardpass(x)\n",
    "        return tf.argmax(tf.nn.softmax(A),axis=1)\n",
    "    def info(self):\n",
    "        num_params=0\n",
    "        for i in range(1,self.L):\n",
    "            num_params+=self.w[i].shape[0]*self.w[i].shape[1]\n",
    "            num_params+=self.b[i].shape[0]\n",
    "            \n",
    "            print(\"Number of Features:{}\".format(self.number_feature))\n",
    "            print(\"Total number of class is:{}\".format(self.num_params))\n",
    "        print(\"Hidden Layer information is :\")\n",
    "        for j in range(1,self.L-1):\n",
    "            print(\"Layers : {}, units{}\".format(i,self.layers[j])\n",
    "            print(\"Total number of parameters :{}\".format(num_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bff81d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (386548191.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [7]\u001b[1;36m\u001b[0m\n\u001b[1;33m    def train(self,x_train,y_train,x_test,y_test,epochs,step_per_epochs,batch_size.lr):\u001b[0m\n\u001b[1;37m                                                                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def train(self,x_train,y_train,x_test,y_test,epochs,step_per_epochs,batch_size.lr):\n",
    "        history={\"val_loss\":[],\"train_loss\":[],\"val_acc\":[]}\n",
    "        for e in range(0,epochs):\n",
    "            training_loss_epochs=0.0\n",
    "            print(\"Epochs {}\"formate(e),\"I\")\n",
    "            for i in range(step_per_epochs):\n",
    "                x_batch=x_train[i*batch_size:(i+1)*batch_size]\n",
    "                y_batch=y_train[i*batch_size:(i+1)*batch_size]\n",
    "                \n",
    "                batch_loss=self.trainig_loss_on_batch(x_batch,y_batch,lr)\n",
    "                epochs_loss_train+=batch_loss\n",
    "                if i%int(step_per_epochs/10)==0 print(end=\".\")\n",
    "                history[\"train_loss\"].append(epochs_loss_train/step_per_epochs)\n",
    "                \n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
